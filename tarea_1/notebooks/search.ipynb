{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Search",
   "id": "fc1f01e42bc891bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: Add language filter",
   "id": "79234f1497ef1c4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "18786dad25968140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from health_topic_index.analysis.parsing import XmlParser",
   "id": "be7d51f686349e30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xml_file_path = '../data/mplus_topics_full.xml'\n",
    "\n",
    "with open(xml_file_path, mode='rb') as file:\n",
    "    document_dict = XmlParser.parse_file(file)\n",
    "\n",
    "health_topics_dict = document_dict['health-topics']\n",
    "health_topics = health_topics_dict['health-topic']\n",
    "id_and_summary = [(ht['id'], ht['full-summary']) for ht in health_topics]\n",
    "documents = [summary for _, summary in id_and_summary]\n",
    "id_to_title = {ht['id']: ht['title'] for ht in health_topics}"
   ],
   "id": "d06987f8d51705eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query = \"feces\"",
   "id": "64bdb4a7ff64391b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cosine Similarity",
   "id": "2b7c217b9f285661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME, cache_folder=\".cache_models\")\n",
    "summary_embeddings = model.encode([summary for _, summary in id_and_summary])"
   ],
   "id": "6c975d8bddce6dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_embedding = model.encode(query)\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding, summary_embeddings)[0].tolist()\n",
    "\n",
    "valid_indices = [i for i in range(len(cosine_scores)) if cosine_scores[i] > 0.3]\n",
    "valid_ids = [ias[0] for i, ias in enumerate(id_and_summary) if i in valid_indices]\n",
    "valid_hts = [ht for ht in health_topics if ht['id'] in valid_ids]\n",
    "\n",
    "for ht in valid_hts:\n",
    "    print(ht['title'])\n",
    "    print()"
   ],
   "id": "45589b5c508a0e47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BM25",
   "id": "1e5acd01a6ee421"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tokenize documents and build BM25\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "bm25 = BM25Okapi(tokenized_docs)"
   ],
   "id": "715a1c07840962c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Query\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Define a minimum relevance score threshold\n",
    "threshold = 3.3\n",
    "\n",
    "# Sort indices by scores in descending order\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "# Filter sorted indices to only keep those with scores above the threshold\n",
    "filtered_sorted_indices = [i for i in sorted_indices if scores[i] >= threshold]\n",
    "\n",
    "# Retrieve valid IDs and corresponding health topics in sorted order\n",
    "sorted_ids = [id_and_summary[i][0] for i in filtered_sorted_indices]\n",
    "sorted_scores = [scores[i] for i in filtered_sorted_indices]\n",
    "sorted_titles = [id_to_title[id] for id in sorted_ids]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "pd.DataFrame({\n",
    "    \"Title\": sorted_titles,\n",
    "    \"Score\": sorted_scores\n",
    "})"
   ],
   "id": "2556a39ff8cd3c65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full results",
   "id": "b7e00ed7fc4e707e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve valid IDs and corresponding health topics in sorted order\n",
    "sorted_ids = [id_and_summary[i][0] for i in sorted_indices]\n",
    "sorted_scores = [scores[i] for i in sorted_indices]\n",
    "sorted_titles = [id_to_title[id] for id in sorted_ids]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": sorted_titles,\n",
    "    \"Score\": sorted_scores\n",
    "})"
   ],
   "id": "37b4df915f035388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BM25 + WordNet",
   "id": "d54386d4d812344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "language = 'eng' # or 'spa' for Spanish",
   "id": "9a4dc6d03994df24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Tokenize documents and build BM25\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "bm25 = BM25Okapi(tokenized_docs)"
   ],
   "id": "a4e45bb7d3cdd786",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to expand a query with synonyms\n",
    "def expand_with_synonyms(tokenized_query):\n",
    "    expanded_query = set(tokenized_query)\n",
    "\n",
    "    for token in tokenized_query:\n",
    "        for syn in wn.synsets(token, lang=language):\n",
    "            for lemma in syn.lemmas(language):\n",
    "                expanded_query.add(lemma.name().replace(\"_\", \" \"))\n",
    "\n",
    "    return list(expanded_query)"
   ],
   "id": "40de3a699b2aa578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Query\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "expanded_query = expand_with_synonyms(tokenized_query)\n",
    "scores = bm25.get_scores(expanded_query)\n",
    "\n",
    "# Define a minimum relevance score threshold\n",
    "threshold = 3.3 # Should probably just list all above zero in order\n",
    "\n",
    "# Sort indices by scores in descending order\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "# Filter sorted indices to only keep those with scores above the threshold\n",
    "filtered_sorted_indices = [i for i in sorted_indices if scores[i] >= threshold]\n",
    "\n",
    "# Retrieve valid IDs and corresponding health topics in sorted order\n",
    "sorted_ids = [id_and_summary[i][0] for i in filtered_sorted_indices]\n",
    "sorted_scores = [scores[i] for i in filtered_sorted_indices]\n",
    "sorted_titles = [id_to_title[id] for id in sorted_ids]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "pd.DataFrame({\n",
    "    \"Title\": sorted_titles,\n",
    "    \"Score\": sorted_scores\n",
    "})"
   ],
   "id": "434a2d22cc14a6ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full results",
   "id": "6c0523a076c8fa0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve valid IDs and corresponding health topics in sorted order\n",
    "sorted_ids = [id_and_summary[i][0] for i in sorted_indices]\n",
    "sorted_scores = [scores[i] for i in sorted_indices]\n",
    "sorted_titles = [id_to_title[id] for id in sorted_ids]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": sorted_titles,\n",
    "    \"Score\": sorted_scores\n",
    "})"
   ],
   "id": "6dbef2c74e6478c3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
